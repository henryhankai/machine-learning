{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Henry Gu - Machine Learning - Homework 2 - Classification\n",
    "\n",
    "## Dataset\n",
    "The dataset you will be using is \"Income\". \n",
    "\n",
    "Features:\n",
    "\n",
    "1. age: continuous.<br>\n",
    "2. workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "3. fnlwgt: continuous.<br>\n",
    "4. education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.<br>\n",
    "5. education-num: continuous.<br>\n",
    "6. marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.<br>\n",
    "7. occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.<br>\n",
    "8. relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.<br>\n",
    "9. race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.<br>\n",
    "10. sex: Female, Male.<br>\n",
    "11. capital-gain: continuous.<br>\n",
    "12. capital-loss: continuous.<br>\n",
    "13. hours-per-week: continuous.<br>\n",
    "14. native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.<br>\n",
    "\n",
    "Target: \n",
    "\n",
    "income: whether a person makes over 50K a year.\n",
    "\n",
    "Prediction task is to determine whether a person makes over 50K a year. (If you transfrom the target as binary values, please make sure >50 is 1, <=50 is 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load relevant packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your training data set and test data\n",
    "income_df = pd.read_csv('income.csv')\n",
    "train_df, test_df = train_test_split(income_df, test_size=0.15, shuffle=True, random_state=11)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Clean the dataset: remove the rows with \" ?\"\n",
    "train_df = train_df[~train_df.select_dtypes(['object']).eq(' ?').any(1)]\n",
    "test_df = test_df[~test_df.select_dtypes(['object']).eq(' ?').any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y\n",
    "X = train_df.drop('income', axis=1)\n",
    "y = train_df['income']\n",
    "\n",
    "X_test = test_df.drop('income', axis=1)\n",
    "y_test = test_df['income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization and One-hot Encoding\n",
    "\n",
    "Standardize the continuous features and convert categorical variables into dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Private</th>\n",
       "      <th>workclass_ Self-emp-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_ Portugal</th>\n",
       "      <th>native-country_ Puerto-Rico</th>\n",
       "      <th>native-country_ Scotland</th>\n",
       "      <th>native-country_ South</th>\n",
       "      <th>native-country_ Taiwan</th>\n",
       "      <th>native-country_ Thailand</th>\n",
       "      <th>native-country_ Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_ United-States</th>\n",
       "      <th>native-country_ Vietnam</th>\n",
       "      <th>native-country_ Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.703239</td>\n",
       "      <td>-0.031963</td>\n",
       "      <td>-1.571753</td>\n",
       "      <td>-0.118600</td>\n",
       "      <td>-0.188716</td>\n",
       "      <td>-0.003894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.366486</td>\n",
       "      <td>-0.595901</td>\n",
       "      <td>-0.350774</td>\n",
       "      <td>-0.118600</td>\n",
       "      <td>-0.188716</td>\n",
       "      <td>-2.112731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.430426</td>\n",
       "      <td>-0.127400</td>\n",
       "      <td>-0.350774</td>\n",
       "      <td>0.965746</td>\n",
       "      <td>-0.188716</td>\n",
       "      <td>-0.003894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.542901</td>\n",
       "      <td>0.168167</td>\n",
       "      <td>1.277198</td>\n",
       "      <td>-0.118600</td>\n",
       "      <td>-0.188716</td>\n",
       "      <td>-0.003894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.104269</td>\n",
       "      <td>-1.399508</td>\n",
       "      <td>0.056219</td>\n",
       "      <td>-0.118600</td>\n",
       "      <td>-0.188716</td>\n",
       "      <td>-0.425661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>0.430426</td>\n",
       "      <td>-0.893852</td>\n",
       "      <td>1.277198</td>\n",
       "      <td>-0.118600</td>\n",
       "      <td>-0.188716</td>\n",
       "      <td>-0.003894</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>-0.018802</td>\n",
       "      <td>0.331170</td>\n",
       "      <td>0.056219</td>\n",
       "      <td>-0.118600</td>\n",
       "      <td>-0.188716</td>\n",
       "      <td>0.333520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>2.077596</td>\n",
       "      <td>-0.760697</td>\n",
       "      <td>-1.978746</td>\n",
       "      <td>-0.118600</td>\n",
       "      <td>-0.188716</td>\n",
       "      <td>-1.353550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>-1.291615</td>\n",
       "      <td>0.377656</td>\n",
       "      <td>0.056219</td>\n",
       "      <td>-0.118600</td>\n",
       "      <td>-0.188716</td>\n",
       "      <td>-0.003894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>-1.291615</td>\n",
       "      <td>1.839465</td>\n",
       "      <td>-2.792732</td>\n",
       "      <td>-0.118600</td>\n",
       "      <td>-0.188716</td>\n",
       "      <td>-1.269196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2903 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age    fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "0     1.703239 -0.031963      -1.571753     -0.118600     -0.188716   \n",
       "1    -1.366486 -0.595901      -0.350774     -0.118600     -0.188716   \n",
       "2     0.430426 -0.127400      -0.350774      0.965746     -0.188716   \n",
       "3    -0.542901  0.168167       1.277198     -0.118600     -0.188716   \n",
       "4     1.104269 -1.399508       0.056219     -0.118600     -0.188716   \n",
       "...        ...       ...            ...           ...           ...   \n",
       "2898  0.430426 -0.893852       1.277198     -0.118600     -0.188716   \n",
       "2899 -0.018802  0.331170       0.056219     -0.118600     -0.188716   \n",
       "2900  2.077596 -0.760697      -1.978746     -0.118600     -0.188716   \n",
       "2901 -1.291615  0.377656       0.056219     -0.118600     -0.188716   \n",
       "2902 -1.291615  1.839465      -2.792732     -0.118600     -0.188716   \n",
       "\n",
       "      hours-per-week  workclass_ Federal-gov  workclass_ Local-gov  \\\n",
       "0          -0.003894                     0.0                   0.0   \n",
       "1          -2.112731                     0.0                   0.0   \n",
       "2          -0.003894                     0.0                   0.0   \n",
       "3          -0.003894                     0.0                   0.0   \n",
       "4          -0.425661                     0.0                   0.0   \n",
       "...              ...                     ...                   ...   \n",
       "2898       -0.003894                     1.0                   0.0   \n",
       "2899        0.333520                     0.0                   0.0   \n",
       "2900       -1.353550                     0.0                   0.0   \n",
       "2901       -0.003894                     0.0                   0.0   \n",
       "2902       -1.269196                     0.0                   0.0   \n",
       "\n",
       "      workclass_ Private  workclass_ Self-emp-inc  ...  \\\n",
       "0                    1.0                      0.0  ...   \n",
       "1                    1.0                      0.0  ...   \n",
       "2                    1.0                      0.0  ...   \n",
       "3                    1.0                      0.0  ...   \n",
       "4                    0.0                      0.0  ...   \n",
       "...                  ...                      ...  ...   \n",
       "2898                 0.0                      0.0  ...   \n",
       "2899                 1.0                      0.0  ...   \n",
       "2900                 1.0                      0.0  ...   \n",
       "2901                 1.0                      0.0  ...   \n",
       "2902                 1.0                      0.0  ...   \n",
       "\n",
       "      native-country_ Portugal  native-country_ Puerto-Rico  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "...                        ...                          ...   \n",
       "2898                       0.0                          0.0   \n",
       "2899                       0.0                          0.0   \n",
       "2900                       0.0                          0.0   \n",
       "2901                       0.0                          0.0   \n",
       "2902                       0.0                          0.0   \n",
       "\n",
       "      native-country_ Scotland  native-country_ South  native-country_ Taiwan  \\\n",
       "0                          0.0                    0.0                     0.0   \n",
       "1                          0.0                    0.0                     0.0   \n",
       "2                          0.0                    0.0                     0.0   \n",
       "3                          0.0                    0.0                     0.0   \n",
       "4                          0.0                    0.0                     0.0   \n",
       "...                        ...                    ...                     ...   \n",
       "2898                       0.0                    0.0                     0.0   \n",
       "2899                       0.0                    0.0                     0.0   \n",
       "2900                       0.0                    0.0                     0.0   \n",
       "2901                       0.0                    0.0                     0.0   \n",
       "2902                       0.0                    0.0                     0.0   \n",
       "\n",
       "      native-country_ Thailand  native-country_ Trinadad&Tobago  \\\n",
       "0                          0.0                              0.0   \n",
       "1                          0.0                              0.0   \n",
       "2                          0.0                              0.0   \n",
       "3                          0.0                              0.0   \n",
       "4                          0.0                              0.0   \n",
       "...                        ...                              ...   \n",
       "2898                       0.0                              0.0   \n",
       "2899                       0.0                              0.0   \n",
       "2900                       0.0                              0.0   \n",
       "2901                       0.0                              0.0   \n",
       "2902                       0.0                              0.0   \n",
       "\n",
       "      native-country_ United-States  native-country_ Vietnam  \\\n",
       "0                               1.0                      0.0   \n",
       "1                               1.0                      0.0   \n",
       "2                               1.0                      0.0   \n",
       "3                               1.0                      0.0   \n",
       "4                               1.0                      0.0   \n",
       "...                             ...                      ...   \n",
       "2898                            1.0                      0.0   \n",
       "2899                            1.0                      0.0   \n",
       "2900                            1.0                      0.0   \n",
       "2901                            1.0                      0.0   \n",
       "2902                            0.0                      0.0   \n",
       "\n",
       "      native-country_ Yugoslavia  \n",
       "0                            0.0  \n",
       "1                            0.0  \n",
       "2                            0.0  \n",
       "3                            0.0  \n",
       "4                            0.0  \n",
       "...                          ...  \n",
       "2898                         0.0  \n",
       "2899                         0.0  \n",
       "2900                         0.0  \n",
       "2901                         0.0  \n",
       "2902                         0.0  \n",
       "\n",
       "[2903 rows x 102 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# standardize all the continuous features\n",
    "col_names_continuous = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "X_scaler = StandardScaler()\n",
    "X_scaler.fit(X[col_names_continuous])\n",
    "X_new_continuous = pd.DataFrame(X_scaler.transform(X[col_names_continuous]), \\\n",
    "                 columns=col_names_continuous)\n",
    "\n",
    "# convert all the categorical variables to dummy variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "col_names_categorical = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "X_enc = OneHotEncoder().fit(X[col_names_categorical])\n",
    "X_new_categorical = X_enc.transform(X[col_names_categorical]).toarray()    \n",
    "X_new_categorical = pd.DataFrame(X_new_categorical, columns=X_enc.get_feature_names(col_names_categorical))\n",
    "\n",
    "# combine continuous and categorical variables into X\n",
    "X = pd.concat([X_new_continuous, X_new_categorical], axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Private</th>\n",
       "      <th>workclass_ Self-emp-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_ Portugal</th>\n",
       "      <th>native-country_ Puerto-Rico</th>\n",
       "      <th>native-country_ Scotland</th>\n",
       "      <th>native-country_ South</th>\n",
       "      <th>native-country_ Taiwan</th>\n",
       "      <th>native-country_ Thailand</th>\n",
       "      <th>native-country_ Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_ United-States</th>\n",
       "      <th>native-country_ Vietnam</th>\n",
       "      <th>native-country_ Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.393158</td>\n",
       "      <td>1.225780</td>\n",
       "      <td>1.277198</td>\n",
       "      <td>-0.1186</td>\n",
       "      <td>-0.188716</td>\n",
       "      <td>-0.003894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.954526</td>\n",
       "      <td>-0.203696</td>\n",
       "      <td>1.277198</td>\n",
       "      <td>-0.1186</td>\n",
       "      <td>-0.188716</td>\n",
       "      <td>-0.003894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.130941</td>\n",
       "      <td>0.059132</td>\n",
       "      <td>1.277198</td>\n",
       "      <td>-0.1186</td>\n",
       "      <td>-0.188716</td>\n",
       "      <td>0.839641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.842387</td>\n",
       "      <td>-0.283503</td>\n",
       "      <td>0.463212</td>\n",
       "      <td>-0.1186</td>\n",
       "      <td>-0.188716</td>\n",
       "      <td>3.370246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.879655</td>\n",
       "      <td>-1.482031</td>\n",
       "      <td>-2.385739</td>\n",
       "      <td>-0.1186</td>\n",
       "      <td>-0.188716</td>\n",
       "      <td>-0.003894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.729912</td>\n",
       "      <td>1.580969</td>\n",
       "      <td>1.277198</td>\n",
       "      <td>-0.1186</td>\n",
       "      <td>-0.188716</td>\n",
       "      <td>0.839641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>1.029397</td>\n",
       "      <td>2.017729</td>\n",
       "      <td>1.684191</td>\n",
       "      <td>-0.1186</td>\n",
       "      <td>-0.188716</td>\n",
       "      <td>-0.003894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>1.478625</td>\n",
       "      <td>-0.645500</td>\n",
       "      <td>-3.199725</td>\n",
       "      <td>-0.1186</td>\n",
       "      <td>-0.188716</td>\n",
       "      <td>-0.003894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>0.580169</td>\n",
       "      <td>-0.945695</td>\n",
       "      <td>1.684191</td>\n",
       "      <td>-0.1186</td>\n",
       "      <td>-0.188716</td>\n",
       "      <td>0.417874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>-0.318287</td>\n",
       "      <td>-1.433328</td>\n",
       "      <td>1.277198</td>\n",
       "      <td>-0.1186</td>\n",
       "      <td>-0.188716</td>\n",
       "      <td>-0.003894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>508 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age    fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "0   -0.393158  1.225780       1.277198       -0.1186     -0.188716   \n",
       "1    0.954526 -0.203696       1.277198       -0.1186     -0.188716   \n",
       "2    0.130941  0.059132       1.277198       -0.1186     -0.188716   \n",
       "3   -0.842387 -0.283503       0.463212       -0.1186     -0.188716   \n",
       "4    0.879655 -1.482031      -2.385739       -0.1186     -0.188716   \n",
       "..        ...       ...            ...           ...           ...   \n",
       "503  0.729912  1.580969       1.277198       -0.1186     -0.188716   \n",
       "504  1.029397  2.017729       1.684191       -0.1186     -0.188716   \n",
       "505  1.478625 -0.645500      -3.199725       -0.1186     -0.188716   \n",
       "506  0.580169 -0.945695       1.684191       -0.1186     -0.188716   \n",
       "507 -0.318287 -1.433328       1.277198       -0.1186     -0.188716   \n",
       "\n",
       "     hours-per-week  workclass_ Federal-gov  workclass_ Local-gov  \\\n",
       "0         -0.003894                     0.0                   0.0   \n",
       "1         -0.003894                     0.0                   0.0   \n",
       "2          0.839641                     0.0                   0.0   \n",
       "3          3.370246                     0.0                   0.0   \n",
       "4         -0.003894                     0.0                   0.0   \n",
       "..              ...                     ...                   ...   \n",
       "503        0.839641                     0.0                   0.0   \n",
       "504       -0.003894                     0.0                   0.0   \n",
       "505       -0.003894                     0.0                   0.0   \n",
       "506        0.417874                     0.0                   0.0   \n",
       "507       -0.003894                     0.0                   0.0   \n",
       "\n",
       "     workclass_ Private  workclass_ Self-emp-inc  ...  \\\n",
       "0                   1.0                      0.0  ...   \n",
       "1                   1.0                      0.0  ...   \n",
       "2                   1.0                      0.0  ...   \n",
       "3                   1.0                      0.0  ...   \n",
       "4                   1.0                      0.0  ...   \n",
       "..                  ...                      ...  ...   \n",
       "503                 0.0                      1.0  ...   \n",
       "504                 1.0                      0.0  ...   \n",
       "505                 1.0                      0.0  ...   \n",
       "506                 1.0                      0.0  ...   \n",
       "507                 1.0                      0.0  ...   \n",
       "\n",
       "     native-country_ Portugal  native-country_ Puerto-Rico  \\\n",
       "0                         0.0                          0.0   \n",
       "1                         0.0                          0.0   \n",
       "2                         0.0                          0.0   \n",
       "3                         0.0                          0.0   \n",
       "4                         0.0                          0.0   \n",
       "..                        ...                          ...   \n",
       "503                       0.0                          0.0   \n",
       "504                       0.0                          0.0   \n",
       "505                       0.0                          0.0   \n",
       "506                       0.0                          0.0   \n",
       "507                       0.0                          0.0   \n",
       "\n",
       "     native-country_ Scotland  native-country_ South  native-country_ Taiwan  \\\n",
       "0                         0.0                    0.0                     0.0   \n",
       "1                         0.0                    0.0                     0.0   \n",
       "2                         0.0                    0.0                     0.0   \n",
       "3                         0.0                    0.0                     0.0   \n",
       "4                         0.0                    0.0                     0.0   \n",
       "..                        ...                    ...                     ...   \n",
       "503                       0.0                    0.0                     0.0   \n",
       "504                       0.0                    0.0                     0.0   \n",
       "505                       0.0                    0.0                     0.0   \n",
       "506                       0.0                    0.0                     0.0   \n",
       "507                       0.0                    0.0                     0.0   \n",
       "\n",
       "     native-country_ Thailand  native-country_ Trinadad&Tobago  \\\n",
       "0                         0.0                              0.0   \n",
       "1                         0.0                              0.0   \n",
       "2                         0.0                              0.0   \n",
       "3                         0.0                              0.0   \n",
       "4                         0.0                              0.0   \n",
       "..                        ...                              ...   \n",
       "503                       0.0                              0.0   \n",
       "504                       0.0                              0.0   \n",
       "505                       0.0                              0.0   \n",
       "506                       0.0                              0.0   \n",
       "507                       0.0                              0.0   \n",
       "\n",
       "     native-country_ United-States  native-country_ Vietnam  \\\n",
       "0                              1.0                      0.0   \n",
       "1                              0.0                      0.0   \n",
       "2                              1.0                      0.0   \n",
       "3                              1.0                      0.0   \n",
       "4                              1.0                      0.0   \n",
       "..                             ...                      ...   \n",
       "503                            1.0                      0.0   \n",
       "504                            1.0                      0.0   \n",
       "505                            0.0                      0.0   \n",
       "506                            1.0                      0.0   \n",
       "507                            1.0                      0.0   \n",
       "\n",
       "     native-country_ Yugoslavia  \n",
       "0                           0.0  \n",
       "1                           0.0  \n",
       "2                           0.0  \n",
       "3                           0.0  \n",
       "4                           0.0  \n",
       "..                          ...  \n",
       "503                         0.0  \n",
       "504                         0.0  \n",
       "505                         0.0  \n",
       "506                         0.0  \n",
       "507                         0.0  \n",
       "\n",
       "[508 rows x 102 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repeat the above steps for the test data\n",
    "# ensure we use the objects fit on the training data to transform test data\n",
    "X_test_continuous = pd.DataFrame(X_scaler.transform(X_test[col_names_continuous]), \\\n",
    "                 columns=col_names_continuous)\n",
    "X_test_categorical = X_enc.transform(X_test[col_names_categorical]).toarray()\n",
    "X_test_categorical = pd.DataFrame(X_test_categorical, columns=X_enc.get_feature_names(col_names_categorical))    \n",
    "\n",
    "X_test = pd.concat([X_test_continuous, X_test_categorical], axis=1)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting training data into training and validation set (the code has been provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.iloc[:2400,:]\n",
    "y_train = y.iloc[:2400]\n",
    "X_val = X.iloc[2400:,:]\n",
    "y_val = y.iloc[2400:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the shape of your X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 102)\n",
      "(503, 102)\n",
      "(508, 102)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the output for validation dataset\n",
    "y_pred = lr.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement precision(), recall(), accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y, y_preds):\n",
    "    \"\"\"\n",
    "    Return precision, which is TP/(TP+FP)\n",
    "    \"\"\"\n",
    "    # function takes two arrays as inputs\n",
    "    \n",
    "    # convert input arrays into a dataframe\n",
    "    df = pd.DataFrame({'y': y, 'y_pred': y_preds})\n",
    "    \n",
    "    # define the second unique value of y_preds as the positive case\n",
    "    # this will be '1' if y_preds is a binary variable\n",
    "    df = df[df['y_pred'] == np.unique(y)[1]]\n",
    "    \n",
    "    # count TP and FP\n",
    "    TP = np.count_nonzero(df['y'] == np.unique(y)[1])\n",
    "    FP = np.count_nonzero(df['y'] == np.unique(y)[0])\n",
    "\n",
    "    return(TP / (TP + FP))\n",
    "\n",
    "def recall(y, y_preds):\n",
    "    \"\"\"\n",
    "    Return recall, which is TP/(TP+FN)\n",
    "    \"\"\"\n",
    "    # function takes two arrays as inputs\n",
    "    \n",
    "    # convert input arrays into a dataframe    \n",
    "    df = pd.DataFrame({'y': y, 'y_pred': y_preds})\n",
    "    \n",
    "    # define the second unique value of y as the positive case\n",
    "    # this will be '1' if y is a binary variable\n",
    "    df = df[df['y'] == np.unique(y)[1]]\n",
    "    \n",
    "    # count TP and FN\n",
    "    TP = np.count_nonzero(df['y_pred'] == np.unique(y)[1])\n",
    "    FN = np.count_nonzero(df['y_pred'] == np.unique(y)[0])    \n",
    "    \n",
    "    return(TP / (TP +  FN))\n",
    "\n",
    "\n",
    "def accuracy(y, y_preds):\n",
    "    \"\"\"\n",
    "    Return accuracy, which is (TP+TN)/(TP+FP+FN+TN)\n",
    "    \"\"\"\n",
    "    # function takes two arrays as inputs\n",
    "    \n",
    "    # convert input arrays into a dataframe\n",
    "    df = pd.DataFrame({'y': y, 'y_pred': y_preds})\n",
    "    \n",
    "    # count TP, TN, FP, FN\n",
    "    # function assumes the inputs y and y_preds have the same categories\n",
    "    # function defines the second unique value of y as the positive case\n",
    "    TP = np.count_nonzero(np.logical_and(df['y'] == np.unique(y)[1], df['y_pred'] == np.unique(y)[1]))\n",
    "    TN = np.count_nonzero(np.logical_and(df['y'] == np.unique(y)[0], df['y_pred'] == np.unique(y)[0]))\n",
    "    FP = np.count_nonzero(np.logical_and(df['y'] == np.unique(y)[0], df['y_pred'] == np.unique(y)[1]))                     \n",
    "    FN = np.count_nonzero(np.logical_and(df['y'] == np.unique(y)[1], df['y_pred'] == np.unique(y)[0]))\n",
    "    return((TP + TN) / (TP + FP + FN + TN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate precision, recall, and accuracy of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  89.46%\n",
      "Precision: 62.50%\n",
      "Recall:    25.42%\n"
     ]
    }
   ],
   "source": [
    "# Using the predictions to calculate accuracy, precision, recall\n",
    "print(f\"{'Accuracy:':<10} {accuracy(y_val.to_numpy(), y_pred) * 100:>5.2f}%\")\n",
    "print(f\"{'Precision:':<10} {precision(y_val.to_numpy(), y_pred) * 100:>5.2f}%\")\n",
    "print(f\"{'Recall:':<10} {recall(y_val.to_numpy(), y_pred) * 100:>5.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "# compute the roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_val, lr.decision_function(X_val), pos_label = np.unique(y_val)[1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "title = f'ROC curve, AUC = {roc_auc:.3f}'\n",
    "plt.plot(fpr, tpr, color='red')\n",
    "plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test performance on various Logistic Regression models with different penalty, C and solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(y_true, y_pred):\n",
    "    print(f\"{'Accuracy:':<10} {accuracy(y_true, y_pred) * 100:>5.2f}%\")\n",
    "    print(f\"{'Precision:':<10} {precision(y_true, y_pred) * 100:>5.2f}%\")\n",
    "    print(f\"{'Recall:':<10} {recall(y_true, y_pred) * 100:>5.2f}%\")\n",
    "    \n",
    "def get_logistic_model_prediction(X_train, y_train, X_test, penalty='l2', C=1.0, solver='lbfgs', max_iter=100):\n",
    "    return LogisticRegression(penalty=penalty, C=C, solver=solver, max_iter=max_iter).fit(X_train,y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  90.06%\n",
      "Precision: 84.62%\n",
      "Recall:    18.64%\n"
     ]
    }
   ],
   "source": [
    "# l1 penalty \n",
    "# C = 0.1\n",
    "# saga solver\n",
    "\n",
    "print_results(y_val.to_numpy(), get_logistic_model_prediction(X_train, y_train, X_val, penalty='l1', C=0.1, solver='saga', max_iter=5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  90.06%\n",
      "Precision: 84.62%\n",
      "Recall:    18.64%\n"
     ]
    }
   ],
   "source": [
    "# l1 penalty \n",
    "# C = 0.1\n",
    "# liblinear solver\n",
    "\n",
    "print_results(y_val.to_numpy(), get_logistic_model_prediction(X_train, y_train, X_val, penalty='l1', C=0.1, solver='liblinear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  89.86%\n",
      "Precision: 66.67%\n",
      "Recall:    27.12%\n"
     ]
    }
   ],
   "source": [
    "# l1 penalty \n",
    "# C = 0.5\n",
    "# saga solver\n",
    "\n",
    "print_results(y_val.to_numpy(), get_logistic_model_prediction(X_train, y_train, X_val, penalty='l1', C=0.5, solver='saga', max_iter=5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  89.86%\n",
      "Precision: 66.67%\n",
      "Recall:    27.12%\n"
     ]
    }
   ],
   "source": [
    "# l1 penalty \n",
    "# C = 0.5\n",
    "# liblinear solver\n",
    "\n",
    "print_results(y_val.to_numpy(), get_logistic_model_prediction(X_train, y_train, X_val, penalty='l1', C=0.5, solver='liblinear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  89.07%\n",
      "Precision: 62.50%\n",
      "Recall:    16.95%\n"
     ]
    }
   ],
   "source": [
    "# l2 penalty \n",
    "# C = 0.1\n",
    "# saga solver\n",
    "\n",
    "print_results(y_val.to_numpy(), get_logistic_model_prediction(X_train, y_train, X_val, penalty='l2', C=0.1, solver='saga', max_iter=5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  89.26%\n",
      "Precision: 64.71%\n",
      "Recall:    18.64%\n"
     ]
    }
   ],
   "source": [
    "# l2 penalty \n",
    "# C = 0.1\n",
    "# saga solver\n",
    "\n",
    "print_results(y_val.to_numpy(), get_logistic_model_prediction(X_train, y_train, X_val, penalty='l2', C=0.1, solver='liblinear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  89.46%\n",
      "Precision: 62.50%\n",
      "Recall:    25.42%\n"
     ]
    }
   ],
   "source": [
    "# l2 penalty \n",
    "# C = 0.5\n",
    "# saga solver\n",
    "\n",
    "print_results(y_val.to_numpy(), get_logistic_model_prediction(X_train, y_train, X_val, penalty='l2', C=0.5, solver='saga', max_iter=5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  89.46%\n",
      "Precision: 62.50%\n",
      "Recall:    25.42%\n"
     ]
    }
   ],
   "source": [
    "# l2 penalty \n",
    "# C = 0.5\n",
    "# liblinear solver\n",
    "\n",
    "print_results(y_val.to_numpy(), get_logistic_model_prediction(X_train, y_train, X_val, penalty='l2', C=0.5, solver='liblinear', max_iter=5000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model\n",
    "Calculate metrics for the best model given the hyperparameter testing above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  91.14%\n",
      "Precision: 80.00%\n",
      "Recall:    22.22%\n"
     ]
    }
   ],
   "source": [
    "lr_final = LogisticRegression(penalty='l1', C=0.1, solver='saga', max_iter=5000).fit(X, y)\n",
    "y_pred = lr_final.predict(X_test)\n",
    "\n",
    "print_results(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
